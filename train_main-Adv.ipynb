{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85ea171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "from utils_data import *\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "from models import Glow\n",
    "from models.glow.coupling import UNet1\n",
    "import util\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as sched\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c084c410",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--mode', type=str, default='ct')\n",
    "parser.add_argument('--noise_level', type=list, default=[5000]) # For PET-CT, noise_level = [PET, CT]\n",
    "parser.add_argument('--semi_sup', type=bool, default=True)\n",
    "parser.add_argument('--supervision', type=float, default=0.0)\n",
    "parser.add_argument('--secondary_noisy', type=int, default=0)\n",
    "parser.add_argument('--resume_training', type=int, default=0)\n",
    "parser.add_argument('--train_size', type=int, default=200)\n",
    "parser.add_argument('--blur_mode',type=str, default=None)\n",
    "parser.add_argument('--new_range',type=int, default=2)\n",
    "\n",
    "parser.add_argument('--transfer_learning', type=bool, default=False)\n",
    "parser.add_argument('--transfer_path', type=str, default='../results200_nd/unet_var_multi5/e3sgdws_petct_bpetnoperc_unet_var_ggg_multif_semi_0.0005-5000_0.5/model_400.ckpt')\n",
    "\n",
    "parser.add_argument('--n_samples', type=int, default=1)\n",
    "parser.add_argument('--s_samples', type=int, default=1)\n",
    "parser.add_argument('--batch_size', type=int, default=1)\n",
    "parser.add_argument('--epoch_num', type=int, default=500)\n",
    "parser.add_argument('--lr', type=float, default=1e-3)\n",
    "parser.add_argument('--device', type=str, default='cuda:4')\n",
    "parser.add_argument('--perceptual', type=bool, default=False)\n",
    "parser.add_argument('--weights',type=tuple,default=[1, 1, 1]) #(pet, ct, latent)\n",
    "parser.add_argument('--target',type=str,default=None)\n",
    "\n",
    "eps=.1\n",
    "alp=.01\n",
    "it=5\n",
    "p='inf'\n",
    "parser.add_argument('--save', type=bool, default=True)\n",
    "parser.add_argument('--path', type=str, default='../results_adv/e3adam_e'+str(eps)+'_a'+str(alp)+'_i'+str(it)+'_p'+str(p)+'_')\n",
    "parser.add_argument('--save_path', type=str, default='')\n",
    "parser.add_argument('--save_path_fig', type=str, default='')\n",
    "\n",
    "def str2bool(s):\n",
    "    return s.lower().startswith('t')\n",
    "parser.add_argument('--num_levels', '-L', default=4, type=int, help='Number of levels in the Glow model')\n",
    "parser.add_argument('--num_steps', '-K', default=8, type=int, help='Number of steps of flow in each level')\n",
    "parser.add_argument('--cc', type = str2bool, default = False)\n",
    "parser.add_argument('--warm_up', default=500000, type=int, help='Number of steps for lr warm-up')\n",
    "parser.add_argument('--ext', default = 'll', type=str)\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "# args_check(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9222d574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 1, 512, 512) (326, 1, 512, 512)\n",
      "same used\n"
     ]
    }
   ],
   "source": [
    "trainloader, testloader, validloader = load_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6103a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results_adv/e3adam_e0.1_a0.01_i5_pinf_ct_same_semi_5000_0.0\n",
      "Create path : ../results_adv/e3adam_e0.1_a0.01_i5_pinf_ct_same_semi_5000_0.0\n"
     ]
    }
   ],
   "source": [
    "args = create_save_path(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fd08276",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Glow(num_channels=1,\n",
    "               num_levels=args.num_levels,\n",
    "               num_steps=args.num_steps,\n",
    "               inp_channel=1,\n",
    "               cond_channel=1,\n",
    "               cc = args.cc)\n",
    "net = net.to(args.device)\n",
    "cudnn.benchmark = True\n",
    "# if device == 'cuda':\n",
    "#     net = torch.nn.DataParallel(net, args.gpu_ids)\n",
    "#     cudnn.benchmark = args.benchmark\n",
    "\n",
    "if args.resume_training!=0:\n",
    "    net.load_state_dict(torch.load(args.save_path+'/model_'+str(args.resume_training)+'.ckpt', map_location='cpu'))\n",
    "\n",
    "unet = UNet1(inp_channels=1, op_channels=1)\n",
    "unet = unet.to(args.device)\n",
    "# unet_weights = torch.load('ckpts/unet/best.pth', map_location = args.device)\n",
    "# unet.load_state_dict(unet_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c7a84ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_l2(Z):\n",
    "    \"\"\"Compute norms over all but the first dimension\"\"\"\n",
    "    return Z.view(Z.shape[0], -1).norm(dim=1)[:,None,None,None]/np.sqrt(Z.shape[1]*Z.shape[2]*Z.shape[3])\n",
    "\n",
    "def pgd_linf_manual(model, x, cond_x, loss_fn, reverse, epsilon=eps, alpha=alp, num_iter=it, randomize=True, norm=p):\n",
    "    \"\"\" Construct FGSM adversarial examples on the examples X\"\"\"\n",
    "    if randomize:\n",
    "        delta = torch.rand_like(x, requires_grad=True)\n",
    "        delta.data = delta.data * 2 * epsilon - epsilon\n",
    "    else:\n",
    "        delta = torch.zeros_like(x, requires_grad=True)\n",
    "#     losses = []    \n",
    "    for t in range(num_iter):\n",
    "        z, sldj = net(x, cond_x+delta, reverse=False)\n",
    "        latent_loss = loss_fn(z, sldj)\n",
    "#         losses.append(latent_loss.item())\n",
    "        latent_loss.backward()\n",
    "        if norm=='l2':\n",
    "            delta.data += alpha*delta.grad.detach() / norm_l2(delta.grad.detach())\n",
    "            delta.data = torch.min(torch.max(delta.detach(), -X), 1-X) # clip X+delta to [0,1]\n",
    "            delta.data *= epsilon / norm_l2(delta.detach()).clamp(min=epsilon)\n",
    "        elif norm=='inf':\n",
    "            delta.data = (delta + alpha*delta.grad.detach().sign()).clamp(-epsilon,epsilon)\n",
    "        delta.grad.zero_()\n",
    "#     plt.plot(losses)\n",
    "#     plt.show()\n",
    "\n",
    "    if torch.mean(delta).isnan():\n",
    "        print(\"delta is nan\")\n",
    "        delta=torch.zeros_like(X)\n",
    "    return delta.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42971339",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.enable_grad()\n",
    "def train(epoch, net, trainloader, device, optimizer, scheduler, loss_fn, max_grad_norm = -1, type = 'ct', args = None, model = None, epsilon = 1e-1):\n",
    "    global global_step\n",
    "    global_step = 0\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    latent_loss_m = util.AverageMeter()\n",
    "    spatial_loss_m = util.AverageMeter()\n",
    "    idx1, idx2 = get_idx(type)\n",
    "    smooth_l1_loss = torch.nn.SmoothL1Loss().to(device)\n",
    "\n",
    "    with tqdm(total=len(trainloader.dataset)) as progress_bar:\n",
    "        for i, x_prime in enumerate(trainloader):\n",
    "            x = x_prime[0] #x_prime[:, idx1, :, :]\n",
    "            cond_x = x_prime[1] #x_prime[:, idx2, :, :]\n",
    "#             mask = x_prime[:, 4, :, :].unsqueeze(1).to(device)\n",
    "#             mask = torch.where(mask > 0, 1, 0)\n",
    "            if len(x.shape) < 4:\n",
    "                x = x.unsqueeze(1)\n",
    "            if len(cond_x.shape) < 4:\n",
    "                cond_x = cond_x.unsqueeze(1)\n",
    "            x, cond_x = x.to(device), cond_x.to(device)\n",
    "#             cond_x.requires_grad = True\n",
    "\n",
    "            # Adversarial \n",
    "            delta = pgd_linf_manual(net, x, cond_x, loss_fn, reverse=False)\n",
    "            z, sldj = net(x, cond_x+delta, reverse=False)\n",
    "\n",
    "            if args.ext == 'll+sl_pl' or args.ext == 'll+sl_l1':\n",
    "                ;\n",
    "            elif args.ext == 'll':\n",
    "                optimizer.zero_grad()\n",
    "                latent_loss = loss_fn(z, sldj)\n",
    "                latent_loss.backward()\n",
    "                if max_grad_norm > 0:\n",
    "                    util.clip_grad_norm(optimizer, max_grad_norm)\n",
    "                optimizer.step()\n",
    "#                 scheduler.step(global_step)\n",
    "\n",
    "                latent_loss_m.update(latent_loss.item(), x.size(0))\n",
    "                progress_bar.set_postfix(nll=latent_loss_m.avg,\n",
    "                                        bpd=util.bits_per_dim(x, latent_loss_m.avg),\n",
    "                                        lr=optimizer.param_groups[0]['lr'])\n",
    "                progress_bar.update(x.size(0))\n",
    "#                 global_step += x.size(0)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(epoch, net, testloader, device, args, path, history = []):\n",
    "    global best_ssim\n",
    "    global best_epoch\n",
    "    net.eval()\n",
    "\n",
    "    rrmse_val, psnr_val, ssim_val = evaluate_1c(net, testloader, device, args.mode)\n",
    "    ssim = np.mean(ssim_val)\n",
    "    flag = True\n",
    "    history.append(ssim)\n",
    "\n",
    "    # Save checkpoint\n",
    "    if torch.isnan(torch.tensor(ssim)):\n",
    "        return True\n",
    "\n",
    "    if flag and ssim > best_ssim:\n",
    "        print('Saving...')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'ssim': ssim,\n",
    "            'rrmse': np.mean(rrmse_val),\n",
    "            'psnr': np.mean(psnr_val),\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        path1 = '/'.join(path.split('/')[:-1])\n",
    "        os.makedirs(path1, exist_ok=True)\n",
    "        torch.save(state, path)        \n",
    "        best_ssim = ssim\n",
    "        best_epoch = epoch\n",
    "\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5c7633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:48<00:00,  1.74s/it, bpd=10.7, lr=0.001, nll=1.95e+6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:41<00:00,  1.71s/it, bpd=10.3, lr=0.001, nll=1.88e+6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:44<00:00,  1.72s/it, bpd=10.3, lr=0.001, nll=1.87e+6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:47<00:00,  1.74s/it, bpd=10.3, lr=0.001, nll=1.87e+6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:45<00:00,  1.73s/it, bpd=10.2, lr=0.001, nll=1.86e+6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:48<00:00,  1.74s/it, bpd=10.2, lr=0.001, nll=1.85e+6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:47<00:00,  1.74s/it, bpd=10.2, lr=0.001, nll=1.85e+6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:46<00:00,  1.73s/it, bpd=10.2, lr=0.001, nll=1.85e+6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:46<00:00,  1.73s/it, bpd=10.1, lr=0.001, nll=1.84e+6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:48<00:00,  1.74s/it, bpd=10.1, lr=0.001, nll=1.84e+6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:48<00:00,  1.74s/it, bpd=10.1, lr=0.001, nll=1.84e+6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:50<00:00,  1.75s/it, bpd=10.1, lr=0.001, nll=1.83e+6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:47<00:00,  1.74s/it, bpd=10.1, lr=0.001, nll=1.83e+6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:53<00:00,  1.77s/it, bpd=10.1, lr=0.001, nll=1.83e+6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [06:03<00:00,  1.82s/it, bpd=10.2, lr=0.001, nll=1.85e+6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [06:04<00:00,  1.82s/it, bpd=10.1, lr=0.001, nll=1.83e+6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:44<00:00,  1.72s/it, bpd=10.1, lr=0.001, nll=1.83e+6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:46<00:00,  1.73s/it, bpd=10.1, lr=0.001, nll=1.83e+6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:46<00:00,  1.73s/it, bpd=10.1, lr=0.001, nll=1.83e+6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:46<00:00,  1.73s/it, bpd=10, lr=0.001, nll=1.83e+6]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 127/200 [03:40<02:06,  1.74s/it, bpd=10, lr=0.001, nll=1.82e+6]  "
     ]
    }
   ],
   "source": [
    "loss_fn = util.NLLLoss(k=65535).to(args.device)\n",
    "\n",
    "if 'sgd' in args.path:\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=args.lr)\n",
    "elif 'adam' in args.path:\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=args.lr)\n",
    "scheduler = None #sched.LambdaLR(optimizer, lambda s: min(1., s / args.warm_up))\n",
    "\n",
    "epoch = args.resume_training\n",
    "while epoch <= args.epoch_num:\n",
    "    train(epoch, net, trainloader, args.device, optimizer, scheduler,\n",
    "          loss_fn, type = args.mode, args = args, model=unet)\n",
    "    if (epoch+1)%25==0 and args.save:\n",
    "        #save checkpoint\n",
    "        torch.save(net.state_dict(), args.save_path+'/model_'+str(epoch+1)+'.ckpt')\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cc36f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = test_model(args,net,testloader)\n",
    "print(np.median(errors,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bfc5ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8ea0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
