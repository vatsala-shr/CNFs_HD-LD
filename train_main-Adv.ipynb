{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85ea171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "from utils_data import *\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "from models import Glow\n",
    "from models.glow.coupling import UNet1\n",
    "import util\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as sched\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c084c410",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--mode', type=str, default='petgc')\n",
    "parser.add_argument('--noise_level', type=list, default=[20]) # For PET-CT, noise_level = [PET, CT]\n",
    "parser.add_argument('--semi_sup', type=bool, default=True)\n",
    "parser.add_argument('--supervision', type=float, default=0.0)\n",
    "parser.add_argument('--secondary_noisy', type=int, default=0)\n",
    "parser.add_argument('--resume_training', type=int, default=0)\n",
    "parser.add_argument('--train_size', type=int, default=800)\n",
    "parser.add_argument('--blur_mode',type=str, default=None)\n",
    "parser.add_argument('--new_range',type=int, default=2)\n",
    "\n",
    "parser.add_argument('--transfer_learning', type=bool, default=False)\n",
    "parser.add_argument('--transfer_path', type=str, default='../results200_nd/unet_var_multi5/e3sgdws_petct_bpetnoperc_unet_var_ggg_multif_semi_0.0005-5000_0.5/model_400.ckpt')\n",
    "\n",
    "parser.add_argument('--batch_size', type=int, default=4)\n",
    "parser.add_argument('--epoch_num', type=int, default=300)\n",
    "parser.add_argument('--lr', type=float, default=1e-3)\n",
    "parser.add_argument('--device', type=str, default='cuda:4')\n",
    "parser.add_argument('--weights',type=tuple,default=[1, 1, 1]) #(pet, ct, latent)\n",
    "\n",
    "eps=.1\n",
    "alp=.01\n",
    "it=5\n",
    "p='inf'\n",
    "parser.add_argument('--save', type=bool, default=True)\n",
    "parser.add_argument('--path', type=str, default='../results_adv/e3adam_e'+str(eps)+'_a'+str(alp)+'_i'+str(it)+'_p'+str(p)+'_')\n",
    "parser.add_argument('--save_path', type=str, default='')\n",
    "parser.add_argument('--save_path_fig', type=str, default='')\n",
    "\n",
    "parser.add_argument('--num_levels', '-L', default=4, type=int, help='Number of levels in the Glow model')\n",
    "parser.add_argument('--num_steps', '-K', default=8, type=int, help='Number of steps of flow in each level')\n",
    "parser.add_argument('--cc', type = bool, default = False)\n",
    "parser.add_argument('--warm_up', default=500000, type=int, help='Number of steps for lr warm-up')\n",
    "parser.add_argument('--ext', default = 'll', type=str)\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "# args_check(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9222d574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 1, 256, 256) (433, 1, 256, 256)\n",
      "same used\n"
     ]
    }
   ],
   "source": [
    "trainloader, testloader, validloader = load_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6103a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results_adv/e3adam_e0.1_a0.01_i5_pinf_petgc_same_semi_20_0.0\n",
      "Create path : ../results_adv/e3adam_e0.1_a0.01_i5_pinf_petgc_same_semi_20_0.0\n"
     ]
    }
   ],
   "source": [
    "args = create_save_path(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fd08276",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Glow(num_channels=128,\n",
    "               num_levels=args.num_levels,\n",
    "               num_steps=args.num_steps,\n",
    "               inp_channel=1,\n",
    "               cond_channel=1,\n",
    "               cc = args.cc)\n",
    "net = net.to(args.device)\n",
    "cudnn.benchmark = True\n",
    "# if device == 'cuda':\n",
    "#     net = torch.nn.DataParallel(net, args.gpu_ids)\n",
    "#     cudnn.benchmark = args.benchmark\n",
    "\n",
    "if args.resume_training!=0:\n",
    "    net.load_state_dict(torch.load(args.save_path+'/model_'+str(args.resume_training)+'.ckpt', map_location='cpu'))\n",
    "\n",
    "unet = UNet1(inp_channels=1, op_channels=1)\n",
    "unet = unet.to(args.device)\n",
    "# unet_weights = torch.load('ckpts/unet/best.pth', map_location = args.device)\n",
    "# unet.load_state_dict(unet_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a28e9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_l2(Z):\n",
    "    \"\"\"Compute norms over all but the first dimension\"\"\"\n",
    "    return Z.view(Z.shape[0], -1).norm(dim=1)[:,None,None,None]/np.sqrt(Z.shape[1]*Z.shape[2]*Z.shape[3])\n",
    "\n",
    "def pgd_linf_manual(model, x, cond_x, loss_fn, reverse, epsilon=eps, alpha=alp, num_iter=it, randomize=True, norm=p):\n",
    "    \"\"\" Construct FGSM adversarial examples on the examples X\"\"\"\n",
    "    if randomize:\n",
    "        delta = torch.rand_like(x, requires_grad=True)\n",
    "        delta.data = delta.data * 2 * epsilon - epsilon\n",
    "    else:\n",
    "        delta = torch.zeros_like(x, requires_grad=True)\n",
    "#     losses = []    \n",
    "    for t in range(num_iter):\n",
    "        z, sldj = net(x, cond_x+delta, reverse=False)\n",
    "        latent_loss = loss_fn(z, sldj)\n",
    "#         losses.append(latent_loss.item())\n",
    "        latent_loss.backward()\n",
    "        if norm=='l2':\n",
    "            delta.data += alpha*delta.grad.detach() / norm_l2(delta.grad.detach())\n",
    "            delta.data = torch.min(torch.max(delta.detach(), -X), 1-X) # clip X+delta to [0,1]\n",
    "            delta.data *= epsilon / norm_l2(delta.detach()).clamp(min=epsilon)\n",
    "        elif norm=='inf':\n",
    "            delta.data = (delta + alpha*delta.grad.detach().sign()).clamp(-epsilon,epsilon)\n",
    "        delta.grad.zero_()\n",
    "#     plt.plot(losses)\n",
    "#     plt.show()\n",
    "\n",
    "    if torch.mean(delta).isnan():\n",
    "        print(\"delta is nan\")\n",
    "        delta=torch.zeros_like(X)\n",
    "    return delta.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42971339",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.enable_grad()\n",
    "def train(epoch, net, data_loader, device, optimizer, loss_fn, args = None, max_grad_norm = -1, model = None, valid=False):\n",
    "    global global_step\n",
    "    global_step = 0\n",
    "    net.train()\n",
    "    latent_loss_m = []\n",
    "    spatial_loss_m = util.AverageMeter()\n",
    "    smooth_l1_loss = torch.nn.SmoothL1Loss().to(device)\n",
    "\n",
    "    for i, x_prime in enumerate(data_loader):\n",
    "        x = x_prime[0] #x_prime[:, idx1, :, :]\n",
    "        cond_x = x_prime[1] #x_prime[:, idx2, :, :]\n",
    "        if len(x.shape) < 4:\n",
    "            x = x.unsqueeze(1)\n",
    "        if len(cond_x.shape) < 4:\n",
    "            cond_x = cond_x.unsqueeze(1)\n",
    "        x, cond_x = x.to(device), cond_x.to(device)\n",
    "\n",
    "        # Adversarial \n",
    "        delta = pgd_linf_manual(net, x, cond_x, loss_fn, reverse=False)\n",
    "        z, sldj = net(x, cond_x+delta, reverse=False)\n",
    "        \n",
    "        if valid==True:\n",
    "            latent_loss = loss_fn(z, sldj)\n",
    "            latent_loss_m.append(latent_loss.item())\n",
    "        else:\n",
    "            if args.ext == 'll+sl_pl' or args.ext == 'll+sl_l1':\n",
    "                ;\n",
    "            elif args.ext == 'll':\n",
    "                optimizer.zero_grad()\n",
    "                latent_loss = loss_fn(z, sldj)\n",
    "                latent_loss.backward()\n",
    "                if max_grad_norm > 0:\n",
    "                    util.clip_grad_norm(optimizer, max_grad_norm)\n",
    "                optimizer.step()\n",
    "    #                 scheduler.step(global_step)\n",
    "\n",
    "                latent_loss_m.append(latent_loss.item())\n",
    "            \n",
    "    return sum(latent_loss_m) / len(latent_loss_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e5c7633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 300/300 [38:54:53<00:00, 466.98s/it, lr=0.001, nll=3.83e+5]   \n"
     ]
    }
   ],
   "source": [
    "loss_fn = util.NLLLoss(k=65535).to(args.device)\n",
    "\n",
    "if 'sgd' in args.path:\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=args.lr)\n",
    "elif 'adam' in args.path:\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=args.lr)\n",
    "scheduler = None #sched.LambdaLR(optimizer, lambda s: min(1., s / args.warm_up))\n",
    "\n",
    "epoch = args.resume_training\n",
    "train_loss = valid_loss = []\n",
    "\n",
    "with tqdm(total = (args.epoch_num-args.resume_training), desc = \"Epoch\") as progress_bar:\n",
    "    while epoch < args.epoch_num:\n",
    "        loss = train(epoch, net, trainloader, args.device, optimizer, loss_fn, args)\n",
    "\n",
    "        progress_bar.set_postfix(nll=loss, lr=optimizer.param_groups[0]['lr'])\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        if epoch%5==0:\n",
    "            train_loss.append(loss)\n",
    "            lossv = train(epoch, net, validloader, args.device, optimizer, loss_fn, args, valid=True)\n",
    "            valid_loss.append(lossv)\n",
    "\n",
    "        if (epoch+1)%25==0 and args.save:\n",
    "            #save checkpoint\n",
    "            torch.save(net.state_dict(), args.save_path+'/model_'+str(epoch+1)+'.ckpt')\n",
    "\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d424ed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_loss, label='train loss')\n",
    "plt.plot(valid_loss, label='valid loss')\n",
    "# plt.ylim(0,2e9)\n",
    "# plt.xlim(100,120)\n",
    "plt.legend()\n",
    "\n",
    "if args.save and args.resume_training==0:\n",
    "    plt.savefig(args.save_path+'/loss.png')\n",
    "elif args.save and args.resume_training!=0:\n",
    "    plt.savefig(args.save_path+'/loss_'+str(args.resume_training)+'.png')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10cc36f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/433 [03:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25314447 0.2852884  0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "errors = test_model(args,net,testloader)\n",
    "print(np.median(errors,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bfc5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.median(errors,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8ea0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
