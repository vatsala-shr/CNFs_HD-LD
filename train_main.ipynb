{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5f918b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "from utils_data import *\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "from models import Glow\n",
    "from models.glow.coupling import UNet1\n",
    "import util\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as sched\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "725e88a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--mode', type=str, default='ct')\n",
    "parser.add_argument('--noise_level', type=list, default=[5000]) # For PET-CT, noise_level = [PET, CT]\n",
    "parser.add_argument('--semi_sup', type=bool, default=True)\n",
    "parser.add_argument('--supervision', type=float, default=0.0)\n",
    "parser.add_argument('--secondary_noisy', type=bool, default=False)\n",
    "parser.add_argument('--resume_training', type=int, default=0)\n",
    "parser.add_argument('--train_size', type=int, default=200)\n",
    "parser.add_argument('--blur_mode',type=str, default=None)\n",
    "parser.add_argument('--new_range',type=int, default=2)\n",
    "\n",
    "parser.add_argument('--transfer_learning', type=bool, default=False)\n",
    "parser.add_argument('--transfer_path', type=str, default='../results200_nd/unet_var_multi5/e3sgdws_petct_bpetnoperc_unet_var_ggg_multif_semi_0.0005-5000_0.5/model_400.ckpt')\n",
    "\n",
    "parser.add_argument('--batch_size', type=int, default=1)\n",
    "parser.add_argument('--epoch_num', type=int, default=300)\n",
    "parser.add_argument('--lr', type=float, default=1e-4)\n",
    "parser.add_argument('--device', type=str, default='cuda:2')\n",
    "parser.add_argument('--weights',type=tuple,default=[1, 1, 1]) #(pet, ct, latent)\n",
    "\n",
    "parser.add_argument('--save', type=bool, default=True)\n",
    "parser.add_argument('--path', type=str, default='../results/e4adam_')\n",
    "parser.add_argument('--save_path', type=str, default='')\n",
    "parser.add_argument('--save_path_fig', type=str, default='')\n",
    "\n",
    "parser.add_argument('--num_levels', '-L', default=4, type=int, help='Number of levels in the Glow model')\n",
    "parser.add_argument('--num_steps', '-K', default=8, type=int, help='Number of steps of flow in each level')\n",
    "parser.add_argument('--cc', type = bool, default = False)\n",
    "parser.add_argument('--warm_up', default=500000, type=int, help='Number of steps for lr warm-up')\n",
    "parser.add_argument('--ext', default = 'll', type=str)\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "# args_check(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cba01aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 1, 512, 512) (326, 1, 512, 512)\n",
      "same used\n"
     ]
    }
   ],
   "source": [
    "trainloader, testloader, validloader = load_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12bdfc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results/e4adam_ct_same_semi_5000_0.0\n"
     ]
    }
   ],
   "source": [
    "args = create_save_path(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7f369d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Glow(num_channels=1,\n",
    "               num_levels=args.num_levels,\n",
    "               num_steps=args.num_steps,\n",
    "               inp_channel=1,\n",
    "               cond_channel=1,\n",
    "               cc = args.cc)\n",
    "net = net.to(args.device)\n",
    "cudnn.benchmark = True\n",
    "# if device == 'cuda':\n",
    "#     net = torch.nn.DataParallel(net, args.gpu_ids)\n",
    "#     cudnn.benchmark = args.benchmark\n",
    "\n",
    "if args.resume_training!=0:\n",
    "    net.load_state_dict(torch.load(args.save_path+'/model_'+str(args.resume_training)+'.ckpt', map_location='cpu'))\n",
    "\n",
    "unet = UNet1(inp_channels=1, op_channels=1)\n",
    "unet = unet.to(args.device)\n",
    "# unet_weights = torch.load('ckpts/unet/best.pth', map_location = args.device)\n",
    "# unet.load_state_dict(unet_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8750828",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.enable_grad()\n",
    "def train(epoch, net, data_loader, device, optimizer, loss_fn, args = None, max_grad_norm = -1, model = None, valid=False):\n",
    "    global global_step\n",
    "    global_step = 0\n",
    "    net.train()\n",
    "    latent_loss_m = []\n",
    "    spatial_loss_m = util.AverageMeter()\n",
    "\n",
    "    for i, x_prime in enumerate(data_loader):\n",
    "        x = x_prime[0] #x_prime[:, idx1, :, :]\n",
    "        cond_x = x_prime[1] #x_prime[:, idx2, :, :]\n",
    "        if len(x.shape) < 4:\n",
    "            x = x.unsqueeze(1)\n",
    "        if len(cond_x.shape) < 4:\n",
    "            cond_x = cond_x.unsqueeze(1)\n",
    "        x, cond_x = x.to(device), cond_x.to(device)\n",
    "        z, sldj = net(x, cond_x, reverse=False)\n",
    "        \n",
    "        if valid==True:\n",
    "            latent_loss = loss_fn(z, sldj)\n",
    "            latent_loss_m.append(latent_loss.item())\n",
    "        else:\n",
    "            if args.ext == 'll+sl_pl' or args.ext == 'll+sl_l1':\n",
    "                ;\n",
    "            elif args.ext == 'll':\n",
    "                optimizer.zero_grad()\n",
    "                latent_loss = loss_fn(z, sldj)\n",
    "                latent_loss.backward()\n",
    "                if max_grad_norm > 0:\n",
    "                    util.clip_grad_norm(optimizer, max_grad_norm)\n",
    "                optimizer.step()\n",
    "\n",
    "                latent_loss_m.append(latent_loss.item())\n",
    "        \n",
    "    return sum(latent_loss_m) / len(latent_loss_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21df43c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   2%|‚ñè         | 6/300 [07:50<6:15:09, 76.56s/it, lr=0.0001, nll=1.83e+6]"
     ]
    }
   ],
   "source": [
    "loss_fn = util.NLLLoss(k=65535).to(args.device)\n",
    "\n",
    "if 'sgd' in args.path:\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=args.lr)\n",
    "elif 'adam' in args.path:\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=args.lr)\n",
    "    \n",
    "epoch = args.resume_training\n",
    "train_loss = valid_loss = []\n",
    "\n",
    "with tqdm(total = (args.epoch_num-args.resume_training), desc = \"Epoch\") as progress_bar:\n",
    "    while epoch < args.epoch_num:\n",
    "        loss = train(epoch, net, trainloader, args.device, optimizer, loss_fn, args)\n",
    "\n",
    "        progress_bar.set_postfix(nll=loss, lr=optimizer.param_groups[0]['lr'])\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        if epoch%5==0:\n",
    "            train_loss.append(loss)\n",
    "            loss = train(epoch, net, trainloader, args.device, optimizer, loss_fn, args, valid=True)\n",
    "            valid_loss.append(loss)\n",
    "\n",
    "        if (epoch+1)%25==0 and args.save:\n",
    "            #save checkpoint\n",
    "            torch.save(net.state_dict(), args.save_path+'/model_'+str(epoch+1)+'.ckpt')\n",
    "\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871f6da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_loss, label='train loss')\n",
    "plt.plot(valid_loss, label='valid loss')\n",
    "plt.legend()\n",
    "\n",
    "if args.save and args.resume_training==0:\n",
    "    plt.savefig(args.save_path+'/loss.png')\n",
    "elif args.save and args.resume_training!=0:\n",
    "    plt.savefig(args.save_path+'/loss_'+str(args.resume_training)+'.png')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11798f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = test_model(args,net,testloader)\n",
    "print(np.median(errors,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d158d83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
